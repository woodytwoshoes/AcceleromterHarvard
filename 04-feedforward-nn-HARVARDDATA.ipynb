{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "The data preparation is identical to the [previous tutorial](https://jvn.io/aakashns/a1b40b04f5174a18bd05b17e3dffb0f0). We begin by importing the required modules & classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the training data and the labels. We then preprocess the dataframe to fill in the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_series = pd.read_csv('train_time_series.csv',index_col = 'timestamp')\n",
    "\n",
    "train_labels = pd.read_csv('train_labels.csv',index_col = 'timestamp')\n",
    "\n",
    "train_with_labels = pd.concat([train_time_series,train_labels],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 27, 2: 213, 4: 47, 3: 88})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_labels.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_labels.label)[152:170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_labels['label'] = train_with_labels['label'].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_labels = train_with_labels.dropna(subset = ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_with_labels['label'] = train_with_labels['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UTC time</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UTC time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1565109931087</th>\n",
       "      <td>20589</td>\n",
       "      <td>2019-08-06T16:45:31.087</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.053802</td>\n",
       "      <td>-0.987701</td>\n",
       "      <td>0.068985</td>\n",
       "      <td>20589.0</td>\n",
       "      <td>2019-08-06T16:45:31.087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565109931188</th>\n",
       "      <td>20590</td>\n",
       "      <td>2019-08-06T16:45:31.188</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.054031</td>\n",
       "      <td>-1.003616</td>\n",
       "      <td>0.126450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565109931288</th>\n",
       "      <td>20591</td>\n",
       "      <td>2019-08-06T16:45:31.288</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.010880</td>\n",
       "      <td>-0.967575</td>\n",
       "      <td>0.170898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565109931388</th>\n",
       "      <td>20592</td>\n",
       "      <td>2019-08-06T16:45:31.388</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.052841</td>\n",
       "      <td>-0.982330</td>\n",
       "      <td>0.235565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565109931488</th>\n",
       "      <td>20593</td>\n",
       "      <td>2019-08-06T16:45:31.488</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.032974</td>\n",
       "      <td>-1.053207</td>\n",
       "      <td>0.256714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565110305638</th>\n",
       "      <td>24325</td>\n",
       "      <td>2019-08-06T16:51:45.638</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.024384</td>\n",
       "      <td>-0.710709</td>\n",
       "      <td>0.030304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565110305738</th>\n",
       "      <td>24326</td>\n",
       "      <td>2019-08-06T16:51:45.738</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.487228</td>\n",
       "      <td>-1.099136</td>\n",
       "      <td>-0.015213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565110305838</th>\n",
       "      <td>24327</td>\n",
       "      <td>2019-08-06T16:51:45.838</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.369446</td>\n",
       "      <td>-0.968506</td>\n",
       "      <td>0.036713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565110305939</th>\n",
       "      <td>24328</td>\n",
       "      <td>2019-08-06T16:51:45.939</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.167877</td>\n",
       "      <td>-0.802826</td>\n",
       "      <td>0.049805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565110306039</th>\n",
       "      <td>24329</td>\n",
       "      <td>2019-08-06T16:51:46.039</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.689346</td>\n",
       "      <td>-0.991043</td>\n",
       "      <td>0.034973</td>\n",
       "      <td>24329.0</td>\n",
       "      <td>2019-08-06T16:51:46.039</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3741 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unnamed: 0                 UTC time accuracy         x  \\\n",
       "timestamp                                                               \n",
       "1565109931087       20589  2019-08-06T16:45:31.087  unknown -0.053802   \n",
       "1565109931188       20590  2019-08-06T16:45:31.188  unknown -0.054031   \n",
       "1565109931288       20591  2019-08-06T16:45:31.288  unknown -0.010880   \n",
       "1565109931388       20592  2019-08-06T16:45:31.388  unknown  0.052841   \n",
       "1565109931488       20593  2019-08-06T16:45:31.488  unknown  0.032974   \n",
       "...                   ...                      ...      ...       ...   \n",
       "1565110305638       24325  2019-08-06T16:51:45.638  unknown  0.024384   \n",
       "1565110305738       24326  2019-08-06T16:51:45.738  unknown  0.487228   \n",
       "1565110305838       24327  2019-08-06T16:51:45.838  unknown  0.369446   \n",
       "1565110305939       24328  2019-08-06T16:51:45.939  unknown  0.167877   \n",
       "1565110306039       24329  2019-08-06T16:51:46.039  unknown  0.689346   \n",
       "\n",
       "                      y         z  Unnamed: 0                 UTC time  label  \n",
       "timestamp                                                                      \n",
       "1565109931087 -0.987701  0.068985     20589.0  2019-08-06T16:45:31.087      1  \n",
       "1565109931188 -1.003616  0.126450         NaN                      NaN      1  \n",
       "1565109931288 -0.967575  0.170898         NaN                      NaN      1  \n",
       "1565109931388 -0.982330  0.235565         NaN                      NaN      1  \n",
       "1565109931488 -1.053207  0.256714         NaN                      NaN      1  \n",
       "...                 ...       ...         ...                      ...    ...  \n",
       "1565110305638 -0.710709  0.030304         NaN                      NaN      4  \n",
       "1565110305738 -1.099136 -0.015213         NaN                      NaN      4  \n",
       "1565110305838 -0.968506  0.036713         NaN                      NaN      4  \n",
       "1565110305939 -0.802826  0.049805         NaN                      NaN      4  \n",
       "1565110306039 -0.991043  0.034973     24329.0  2019-08-06T16:51:46.039      4  \n",
       "\n",
       "[3741 rows x 9 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_target = 'label'\n",
    "all_covariates = ['x','y','z']\n",
    "\n",
    "targets = np.array(train_with_labels.label,dtype='float32')-1\n",
    "inputs = np.array(train_with_labels[all_covariates],dtype='float32')\n",
    "\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "\n",
    "targets = targets.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.type>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3741"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define and use a function `split_indices` to pick a random 20% fraction of the images for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(n, val_pct):\n",
    "    # Determine size of validation set\n",
    "    n_val = int(val_pct*n)\n",
    "    # Create random permutation of 0 to n-1\n",
    "    idxs = np.random.permutation(n)\n",
    "    # Pick first n_val indices for validation set\n",
    "    return idxs[n_val:], idxs[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2993 748\n",
      "Sample val indices:  [1075 1685 2015 2824  857  720 3428  724 2300 2890 2214 2129 2846 1008\n",
      "  518 1264  546 1244 3607 2627]\n"
     ]
    }
   ],
   "source": [
    "train_indices, val_indices = split_indices(len(dataset), val_pct=0.2)\n",
    "\n",
    "print(len(train_indices), len(val_indices))\n",
    "print('Sample val indices: ', val_indices[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create PyTorch data loaders for each of the subsets using a `SubsetRandomSampler`, which samples elements randomly from a given list of indices, while creating batches of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "\n",
    "# Training sampler and data loader\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_dl = DataLoader(dataset, \n",
    "                      batch_size, \n",
    "                      sampler=train_sampler)\n",
    "\n",
    "# Validation sampler and data loader\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "valid_dl = DataLoader(dataset,\n",
    "                    batch_size, \n",
    "                    sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "To improve upon [logistic regression](https://jvn.io/aakashns/a1b40b04f5174a18bd05b17e3dffb0f0), we'll create a neural network with one **hidden layer**. Here's what this means:\n",
    "\n",
    "* Instead of using a single `nn.Linear` object to transform a batch of inputs (pixel intensities) into a batch of outputs (class probabilities), we'll use two `nn.Linear` objects. Each of these is called a layer in the network. \n",
    "\n",
    "* The first layer (also known as the hidden layer) will transform the input matrix of shape `batch_size x 784` into an intermediate output matrix of shape `batch_size x hidden_size`, where `hidden_size` is a preconfigured parameter (e.g. 32 or 64).\n",
    "\n",
    "* The intermediate outputs are then passed into a non-linear *activation function*, which operates on individual elements of the output matrix.\n",
    "\n",
    "* The result of the activation function, which is also of size `batch_size x hidden_size`, is passed into the second layer (also knowns as the output layer), which transforms it into a matrix of size `batch_size x 10`, identical to the output of the logistic regression model.\n",
    "\n",
    "Introducing a hidden layer and an activation function allows the model to learn more complex, multi-layered and non-linear relationships between the inputs and the targets. Here's what it looks like visually:\n",
    "\n",
    "![](https://i.imgur.com/vDOGEkG.png)\n",
    "\n",
    "The activation function we'll use here is called a **Rectified Linear Unit** or **ReLU**, and it has a really simple formula: `relu(x) = max(0,x)` i.e. if an element is negative, we replace it by 0, otherwise we leave it unchanged.\n",
    "\n",
    "To define the model, we extend the `nn.Module` class, just as we did with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    \"\"\"Feedfoward neural network with 1 hidden layer\"\"\"\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        # hidden layer\n",
    "        self.linear1 = nn.Linear(in_size, hidden_size)\n",
    "        # output layer\n",
    "        self.linear2 = nn.Linear(hidden_size, out_size)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        # Flatten the image tensors\n",
    "        #xb = xb.view(xb.size(0), -1)\n",
    "        # Get intermediate outputs using hidden layer\n",
    "        out = self.linear1(xb)\n",
    "        # Apply activation function\n",
    "        out = F.relu(out)\n",
    "        # Get predictions using output layer\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModelDeep(nn.Module):\n",
    "    \"\"\"Feedfoward neural network with 1 hidden layer\"\"\"\n",
    "    def __init__(self, in_size, hidden_size, hidden_size_2, out_size):\n",
    "        super().__init__()\n",
    "        # hidden layer\n",
    "        self.linear1 = nn.Linear(in_size, hidden_size)\n",
    "        # hidden layer 2\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size_2)\n",
    "        # output layer\n",
    "        self.linear3 = nn.Linear(hidden_size_2, out_size)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        # Flatten the image tensors\n",
    "        #xb = xb.view(xb.size(0), -1)\n",
    "        # Get intermediate outputs using hidden layer\n",
    "        out = self.linear1(xb)\n",
    "        # Apply activation function\n",
    "        out = F.relu(out)\n",
    "        # into hidden layer 2\n",
    "        out = self.linear2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a model that contains a hidden layer with 32 activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3\n",
    "num_classes = 4\n",
    "\n",
    "model = MnistModelDeep(input_size, hidden_size=20, hidden_size_2 = 10,\n",
    "                   out_size=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the model's parameters. We expect to see one weight and bias matrix for each of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3])\n",
      "torch.Size([20])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([10])\n",
      "torch.Size([4, 10])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for t in model.parameters():\n",
    "    print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and generate some outputs using our model. We'll take the first batch of 100 images from our dataset, and pass them into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7128078937530518\n",
      "outputs.shape :  torch.Size([10, 4])\n",
      "Sample outputs :\n",
      " tensor([[ 0.7288,  0.5517, -0.5347, -1.1531],\n",
      "        [-0.2460,  0.6723, -0.2456, -0.5535]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for feature, labels in train_dl:\n",
    "    outputs = model(feature)\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    print('Loss:', loss.item())\n",
    "    break\n",
    "\n",
    "print('outputs.shape : ', outputs.shape)\n",
    "print('Sample outputs :\\n', outputs[:2].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a GPU\n",
    "\n",
    "As the sizes of our models and datasets increase, we need to use GPUs to train our models within a reasonable amount of time. GPUs contain hundreds of cores that are optimized for performing expensive matrix operations on floating point numbers in a short time, which makes them ideal for training deep neural networks with many layers. You can use GPUs for free on [Kaggle kernels](https://www.kaggle.com/kernels) or [Google Colab](https://colab.research.google.com/), or rent GPU-powered machines on services like [Google Cloud Platform](https://cloud.google.com/gpu/), [Amazon Web Services](https://docs.aws.amazon.com/dlami/latest/devguide/gpu.html) or [Paperspace](https://www.paperspace.com/).\n",
    "\n",
    "We can check if a GPU is available and the required NVIDIA CUDA drivers are installed using `torch.cuda.is_available`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a helper function to ensure that our code uses the GPU if available, and defaults to using the CPU if it isn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a function that can move data and model to a chosen device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dl:\n",
    "    print(images.shape)\n",
    "    images = to_device(images, device)\n",
    "    print(images.device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define a `DeviceDataLoader` class to wrap our existing data loaders and move data to the selected device, as a batches are accessed. Interestingly, we don't need to extend an existing class to create a PyTorch dataloader. All we need is an `__iter__` method to retrieve batches of data, and an `__len__` method to get the number of batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now wrap our data loaders using `DeviceDataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "valid_dl = DeviceDataLoader(valid_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors that have been moved to the GPU's RAM have a `device` property which includes the word `cuda`. Let's verify this by looking at a batch of data from `valid_dl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb.device: cuda:0\n",
      "yb: tensor([1, 1, 2, 2, 1, 1, 1, 1, 2, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in valid_dl:\n",
    "    print('xb.device:', xb.device)\n",
    "    print('yb:', yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with logistic regression, we can use cross entropy as the loss function and accuracy as the evaluation metric for our model. The training loop is also identical, so we can reuse the `loss_batch`, `evaluate` and `fit` functions from the previous tutorial. \n",
    "\n",
    "The `loss_batch` function calculates the loss and metric value for a batch of data, and optionally performs gradient descent if an optimizer is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None, metric=None):\n",
    "    # Generate predictions\n",
    "    preds = model(xb)\n",
    "    # Calculate loss\n",
    "    loss = loss_func(preds, yb)\n",
    "                     \n",
    "    if opt is not None:\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update parameters             \n",
    "        opt.step()\n",
    "        # Reset gradients\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    metric_result = None\n",
    "    if metric is not None:\n",
    "        # Compute the metric\n",
    "        metric_result = metric(preds, yb)\n",
    "    \n",
    "    return loss.item(), len(xb), metric_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `evaluate` function calculates the overall loss (and a metric, if provided) for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, valid_dl, metric=None):\n",
    "    with torch.no_grad():\n",
    "        # Pass each batch through the model\n",
    "        results = [loss_batch(model, loss_fn, xb, yb, metric=metric)\n",
    "                   for xb,yb in valid_dl]\n",
    "        # Separate losses, counts and metrics\n",
    "        losses, nums, metrics = zip(*results)\n",
    "        # Total size of the dataset\n",
    "        total = np.sum(nums)\n",
    "        # Avg. loss across batches \n",
    "        avg_loss = np.sum(np.multiply(losses, nums)) / total\n",
    "        avg_metric = None\n",
    "        if metric is not None:\n",
    "            # Avg. of metric across batches\n",
    "            avg_metric = np.sum(np.multiply(metrics, nums)) / total\n",
    "    return avg_loss, total, avg_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit` function contains the actual training loop, as defined ni the previous tutorials. We'll make a couple more enhancements to the `fit` function: \n",
    "\n",
    "* Instead of the defining the optimizer manually, we'll pass in the learning rate and create an optimizer inside the `fit` function. This will allows us to train the model with different learning rates, if required.\n",
    "\n",
    "* We'll record the validation loss and accuracy at the end of every epoch, and return the history as the output of the `fit` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, loss_fn, train_dl, \n",
    "        valid_dl, metric=None, opt_fn=None):\n",
    "    losses, metrics = [], []\n",
    "    \n",
    "    # Instantiate the optimizer\n",
    "    if opt_fn is None: opt_fn = torch.optim.SGD\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        for xb,yb in train_dl:\n",
    "            loss,_,_ = loss_batch(model, loss_fn, xb, yb, opt)\n",
    "\n",
    "        # Evaluation\n",
    "        result = evaluate(model, loss_fn, valid_dl, metric)\n",
    "        val_loss, total, val_metric = result\n",
    "        \n",
    "        # Record the loss & metric\n",
    "        losses.append(val_loss)\n",
    "        metrics.append(val_metric)\n",
    "        \n",
    "        # Print progress\n",
    "        if metric is None:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch+1, epochs, val_loss))\n",
    "        else:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}, {}: {:.4f}'\n",
    "                  .format(epoch+1, epochs, val_loss, \n",
    "                          metric.__name__, val_metric))\n",
    "    return losses, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define an `accuracy` function which calculates the overall accuracy of the model on an entire batch of outputs, so that we can use it as a metric in `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.sum(preds == labels).item() / len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train the model, we need to ensure that the data and the model's parameters (weights and biases) are on the same device (CPU or GPU). We can reuse the `to_device` function to move the model's parameters to the right device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistModelDeep(\n",
       "  (linear1): Linear(in_features=3, out_features=20, bias=True)\n",
       "  (linear2): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (linear3): Linear(in_features=10, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model (on GPU)\n",
    "model = MnistModelDeep(input_size, hidden_size=20, hidden_size_2 = 10,\n",
    "                   out_size=num_classes)\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the model performs on the validation set with the initial set of weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4207, Accuracy: 0.2527\n"
     ]
    }
   ],
   "source": [
    "val_loss, total, val_acc = evaluate(model, F.cross_entropy, \n",
    "                                    valid_dl, metric=accuracy)\n",
    "print('Loss: {:.4f}, Accuracy: {:.4f}'.format(val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial accuracy is around 10%, which is what one might expect from a randomly intialized model (since it has a 1 in 10 chance of getting a label right by guessing randomly).\n",
    "\n",
    "We are now ready to train the model. Let's train for 5 epochs and look at the results. We can use a relatively higher learning of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.0808, accuracy: 0.5441\n",
      "Epoch [2/5], Loss: 1.1393, accuracy: 0.5588\n",
      "Epoch [3/5], Loss: 1.0635, accuracy: 0.5588\n",
      "Epoch [4/5], Loss: 1.1941, accuracy: 0.5588\n",
      "Epoch [5/5], Loss: 1.0152, accuracy: 0.5588\n"
     ]
    }
   ],
   "source": [
    "losses1, metrics1 = fit(5, 0.5, model, F.cross_entropy, \n",
    "                        train_dl, valid_dl, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95% is pretty good! Let's train the model for 5 more epochs at a lower learning rate of 0.1, to further improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.0017, accuracy: 0.5749\n",
      "Epoch [2/5], Loss: 0.9768, accuracy: 0.5816\n",
      "Epoch [3/5], Loss: 0.9722, accuracy: 0.5869\n",
      "Epoch [4/5], Loss: 0.9842, accuracy: 0.5709\n",
      "Epoch [5/5], Loss: 1.0026, accuracy: 0.5762\n"
     ]
    }
   ],
   "source": [
    "losses2, metrics2 = fit(5, 0.1, model, F.cross_entropy, \n",
    "                        train_dl, valid_dl, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the accuracies to study how the model improves over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace these values with your results\n",
    "accuracies = [val_acc] + metrics1 + metrics2\n",
    "plt.plot(accuracies, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our current model outperforms the logistic regression model (which could only reach around 86% accuracy) by a huge margin! It quickly reaches an accuracy of 96%, but doesn't improve much beyond this. To improve the accuracy further, we need to make the model more powerful. As you can probably guess, this can be achieved by increasing the size of the hidden layer, or adding more hidden layers. I encourage you to try out both these approaches and see which one works better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0026, Accuracy: 0.5762\n"
     ]
    }
   ],
   "source": [
    "val_loss, total, val_acc = evaluate(model, F.cross_entropy, \n",
    "                                    valid_dl, metric=accuracy)\n",
    "print('Loss: {:.4f}, Accuracy: {:.4f}'.format(val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move onto the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time_series = pd.read_csv('test_time_series.csv',index_col = 'timestamp')\n",
    "\n",
    "test_labels = pd.read_csv('test_labels.csv',index_col = 'timestamp')\n",
    "\n",
    "test_with_labels = pd.concat([test_time_series,test_labels],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_with_labels = test_with_labels.dropna(subset = ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_target = 'label'\n",
    "all_covariates = ['x','y','z']\n",
    "\n",
    "targets_test = np.array(test_with_labels.label,dtype='float32')-1\n",
    "inputs_test = np.array(test_with_labels[all_covariates],dtype='float32')\n",
    "\n",
    "\n",
    "inputs_test = torch.from_numpy(inputs_test)\n",
    "targets_test = torch.from_numpy(targets_test)\n",
    "\n",
    "targets_test = targets_test.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CUDA but got backend CPU for argument #4 'mat1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-18557932e786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-12231825add5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#xb = xb.view(xb.size(0), -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Get intermediate outputs using hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Apply activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CUDA but got backend CPU for argument #4 'mat1'"
     ]
    }
   ],
   "source": [
    "model(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = TensorDataset(inputs_test, targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(dataset_test,\n",
    "                    batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    for feature, labels in test_dl:\n",
    "        feature = feature.to(device)  # missing line from original code\n",
    "        labels = labels.to(device)  # missing line from original code\n",
    "        out = model(feature)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        predictions+=predicted.tolist()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DeviceDataLoader(test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6311, Accuracy: 0.8640\n"
     ]
    }
   ],
   "source": [
    "test_loss, total, test_acc = evaluate(model, F.cross_entropy, \n",
    "                                    test_dl, metric=accuracy)\n",
    "print('Loss: {:.4f}, Accuracy: {:.4f}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commit and upload the notebook\n",
    "\n",
    "As a final step, we can save and commit our work using the jovian library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Saving notebook..\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Further Reading\n",
    "\n",
    "Here is a summary of the topics covered in this tutorial:\n",
    "\n",
    "* We created a neural network with one hidden layer to improve upon the logistic regression model from the previous tutorial. We also used the ReLU activation function to introduce non-linearity into the model, allowing it to learn more complex relationships between the inputs (pixel densities) and outputs (class probabilities).\n",
    "\n",
    "* We defined some utilities like `get_default_device`, `to_device` and `DeviceDataLoader` to leverage a GPU if available, by moving the input data and model parameters to the appropriate device.\n",
    "\n",
    "* We were able to use the exact same training loop: the `fit` function we had define earlier to train out model and evaluate it using the validation dataset.\n",
    "\n",
    "There's a lot of scope to experiment here, and I encourage you to use the interactive nature of Jupyter to play around with the various parameters. Here are a few ideas:\n",
    "\n",
    "* Try changing the size of the hidden layer, or add more hidden layers and see if you can achieve a higher accuracy.\n",
    "\n",
    "* Try changing the batch size and learning rate to see if you can achieve the same accuracy in fewer epochs.\n",
    "\n",
    "* Compare the training times on a CPU vs. GPU. Do you see a significant difference. How does it vary with the size of the dataset and the size of the model (no. of weights and parameters)?\n",
    "\n",
    "* Try building a model for a different dataset, such as the [CIFAR10 or CIFAR100 datasets](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "Here are some references for further reading:\n",
    "\n",
    "* [A visual proof that neural networks can compute any function](http://neuralnetworksanddeeplearning.com/chap4.html), also known as the Universal Approximation Theorem.\n",
    "\n",
    "* [But what *is* a neural network?](https://www.youtube.com/watch?v=aircAruvnKk) - A visual and intuitive introduction to what neural networks are and what the intermediate layers represent\n",
    "\n",
    "* [Stanford CS229 Lecture notes on Backpropagation](http://cs229.stanford.edu/notes/cs229-notes-backprop.pdf) - for a more mathematical treatment of how gradients are calculated and weights are updated for neural networks with multiple layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
